{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Example\n",
    "This notebook contains a complete example of feature importance for a trained neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "from typing import List, Dict\n",
    "from statistics import mean, stdev\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import HTML\n",
    "from scipy.stats import norm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "matplotlib.rcParams[\"animation.embed_limit\"] = 2**128\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "split = 100\n",
    "\n",
    "\n",
    "def generate_random_values():\n",
    "    return [randint(0, 50) * randint(0, 50) for _ in range(samples)]\n",
    "\n",
    "\n",
    "ms = [2 for _ in range(samples)]\n",
    "xs = generate_random_values()\n",
    "cs = [50 for _ in range(samples)]\n",
    "\n",
    "ys = []\n",
    "for i in range(samples):\n",
    "    y = ms[i] * xs[i] + cs[i]\n",
    "    ys.append(y)\n",
    "noise = [random.randint(0, 100) for _ in range(samples)]\n",
    "\n",
    "data = {\"ms\": ms, \"xs\": xs, \"cs\": cs, \"noise\": noise, \"ys\": ys}\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "train = df.iloc[split:]\n",
    "test = df.iloc[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"ms\", \"xs\", \"cs\", \"noise\"]]\n",
    "y_train = train[\"ys\"]\n",
    "X_test = test[[\"ms\", \"xs\", \"cs\", \"noise\"]]\n",
    "y_test = test[\"ys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_history(columns: int, nodes: int) -> Dict:\n",
    "    return {i:{j: [] for j in range(nodes)} for i in range(columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_LAYER = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = create_history(len(X_train.columns), FIRST_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 23:10:51.638640: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-02 23:10:51.638768: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=FIRST_LAYER, input_shape=[4]))\n",
    "model.add(tf.keras.layers.Dense(units=1))\n",
    "model.summary()\n",
    "opt = Adam(0.01)\n",
    "model.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 23:10:51.784788: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/29 [===========>..................] - ETA: 0s - loss: 127839.7734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 23:10:51.987581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step - loss: 62457.1641\n",
      "RUNNING EPOCH 2\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4359.5967\n",
      "RUNNING EPOCH 3\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1688.0483\n",
      "RUNNING EPOCH 4\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 771.0728\n",
      "RUNNING EPOCH 5\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 436.1665\n",
      "RUNNING EPOCH 6\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 307.6446\n",
      "RUNNING EPOCH 7\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 238.3710\n",
      "RUNNING EPOCH 8\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 188.9178\n",
      "RUNNING EPOCH 9\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 149.2786\n",
      "RUNNING EPOCH 10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 117.3133\n",
      "RUNNING EPOCH 11\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 90.1842\n",
      "RUNNING EPOCH 12\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 66.1937\n",
      "RUNNING EPOCH 13\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 48.9947\n",
      "RUNNING EPOCH 14\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 35.2308\n",
      "RUNNING EPOCH 15\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 25.0437\n",
      "RUNNING EPOCH 16\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 17.2819\n",
      "RUNNING EPOCH 17\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 12.0227\n",
      "RUNNING EPOCH 18\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 8.3280\n",
      "RUNNING EPOCH 19\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.4009\n",
      "RUNNING EPOCH 20\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.5876\n",
      "RUNNING EPOCH 21\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.4293\n",
      "RUNNING EPOCH 22\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.4754\n",
      "RUNNING EPOCH 23\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.9241\n",
      "RUNNING EPOCH 24\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5680\n",
      "RUNNING EPOCH 25\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3462\n",
      "RUNNING EPOCH 26\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2220\n",
      "RUNNING EPOCH 27\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1235\n",
      "RUNNING EPOCH 28\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0721\n",
      "RUNNING EPOCH 29\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0406\n",
      "RUNNING EPOCH 30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0228\n",
      "RUNNING EPOCH 31\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0126\n",
      "RUNNING EPOCH 32\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "RUNNING EPOCH 33\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "RUNNING EPOCH 34\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "RUNNING EPOCH 35\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.9384e-04\n",
      "RUNNING EPOCH 36\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.1547e-04\n",
      "RUNNING EPOCH 37\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.5298e-04\n",
      "RUNNING EPOCH 38\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3348e-04\n",
      "RUNNING EPOCH 39\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.0058e-05\n",
      "RUNNING EPOCH 40\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.9677e-05\n",
      "RUNNING EPOCH 41\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3620e-05\n",
      "RUNNING EPOCH 42\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.9593e-06\n",
      "RUNNING EPOCH 43\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.6838e-06\n",
      "RUNNING EPOCH 44\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1650e-06\n",
      "RUNNING EPOCH 45\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.1221e-07\n",
      "RUNNING EPOCH 46\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.2253e-07\n",
      "RUNNING EPOCH 47\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.0499e-08\n",
      "RUNNING EPOCH 48\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.6580e-08\n",
      "RUNNING EPOCH 49\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.2918e-08\n",
      "RUNNING EPOCH 50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1311e-08\n",
      "RUNNING EPOCH 51\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.9259e-08\n",
      "RUNNING EPOCH 52\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.7285e-08\n",
      "RUNNING EPOCH 53\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6599e-08\n",
      "RUNNING EPOCH 54\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6265e-08\n",
      "RUNNING EPOCH 55\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5442e-08\n",
      "RUNNING EPOCH 56\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6298e-08\n",
      "RUNNING EPOCH 57\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.6230e-08\n",
      "RUNNING EPOCH 58\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6277e-08\n",
      "RUNNING EPOCH 59\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5914e-08\n",
      "RUNNING EPOCH 60\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5922e-08\n",
      "RUNNING EPOCH 61\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6271e-08\n",
      "RUNNING EPOCH 62\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.6473e-08\n",
      "RUNNING EPOCH 63\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4664e-08\n",
      "RUNNING EPOCH 64\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4731e-08\n",
      "RUNNING EPOCH 65\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4728e-08\n",
      "RUNNING EPOCH 66\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4675e-08\n",
      "RUNNING EPOCH 67\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5086e-08\n",
      "RUNNING EPOCH 68\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4905e-08\n",
      "RUNNING EPOCH 69\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.4938e-08\n",
      "RUNNING EPOCH 70\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4907e-08\n",
      "RUNNING EPOCH 71\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5682e-08\n",
      "RUNNING EPOCH 72\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4816e-08\n",
      "RUNNING EPOCH 73\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5635e-08\n",
      "RUNNING EPOCH 74\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5660e-08\n",
      "RUNNING EPOCH 75\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.7207e-08\n",
      "RUNNING EPOCH 76\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.6090e-08\n",
      "RUNNING EPOCH 77\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5327e-08\n",
      "RUNNING EPOCH 78\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5296e-08\n",
      "RUNNING EPOCH 79\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4487e-08\n",
      "RUNNING EPOCH 80\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4587e-08\n",
      "RUNNING EPOCH 81\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4476e-08\n",
      "RUNNING EPOCH 82\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4489e-08\n",
      "RUNNING EPOCH 83\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4531e-08\n",
      "RUNNING EPOCH 84\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3951e-08\n",
      "RUNNING EPOCH 85\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4544e-08\n",
      "RUNNING EPOCH 86\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5432e-08\n",
      "RUNNING EPOCH 87\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1439e-08\n",
      "RUNNING EPOCH 88\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4214e-08\n",
      "RUNNING EPOCH 89\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4416e-08\n",
      "RUNNING EPOCH 90\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3569e-08\n",
      "RUNNING EPOCH 91\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3023e-08\n",
      "RUNNING EPOCH 92\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3381e-08\n",
      "RUNNING EPOCH 93\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3579e-08\n",
      "RUNNING EPOCH 94\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3880e-08\n",
      "RUNNING EPOCH 95\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3909e-08\n",
      "RUNNING EPOCH 96\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3829e-08\n",
      "RUNNING EPOCH 97\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3993e-08\n",
      "RUNNING EPOCH 98\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3904e-08\n",
      "RUNNING EPOCH 99\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3782e-08\n",
      "RUNNING EPOCH 100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.2208e-08\n",
      "RUNNING EPOCH 101\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.4277e-08\n",
      "RUNNING EPOCH 102\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.5817e-08\n",
      "RUNNING EPOCH 103\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.7257e-08\n",
      "RUNNING EPOCH 104\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.0223e-08\n",
      "RUNNING EPOCH 105\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.9911e-08\n",
      "RUNNING EPOCH 106\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3777e-08\n",
      "RUNNING EPOCH 107\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3938e-08\n",
      "RUNNING EPOCH 108\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.4435e-08\n",
      "RUNNING EPOCH 109\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4594e-08\n",
      "RUNNING EPOCH 110\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.7961e-08\n",
      "RUNNING EPOCH 111\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.5215e-08\n",
      "RUNNING EPOCH 112\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.5177e-08\n",
      "RUNNING EPOCH 113\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.4200e-08\n",
      "RUNNING EPOCH 114\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4361e-08\n",
      "RUNNING EPOCH 115\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.5122e-08\n",
      "RUNNING EPOCH 116\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1546e-08\n",
      "RUNNING EPOCH 117\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.8438e-08\n",
      "RUNNING EPOCH 118\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7239e-08\n",
      "RUNNING EPOCH 119\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.3505e-08\n",
      "RUNNING EPOCH 120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.3290e-08\n",
      "RUNNING EPOCH 121\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4491e-08\n",
      "RUNNING EPOCH 122\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3666e-08\n",
      "RUNNING EPOCH 123\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3298e-08\n",
      "RUNNING EPOCH 124\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1291e-08\n",
      "RUNNING EPOCH 125\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.6053e-08\n",
      "RUNNING EPOCH 126\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.9959e-08\n",
      "RUNNING EPOCH 127\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6653e-08\n",
      "RUNNING EPOCH 128\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.8999e-08\n",
      "RUNNING EPOCH 129\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.6553e-08\n",
      "RUNNING EPOCH 130\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.0465e-08\n",
      "RUNNING EPOCH 131\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.0079e-08\n",
      "RUNNING EPOCH 132\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.0170e-08\n",
      "RUNNING EPOCH 133\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.7475e-08\n",
      "RUNNING EPOCH 134\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.3064e-08\n",
      "RUNNING EPOCH 135\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.3361e-08\n",
      "RUNNING EPOCH 136\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.6643e-08\n",
      "RUNNING EPOCH 137\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.0797e-08\n",
      "RUNNING EPOCH 138\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.0116e-08\n",
      "RUNNING EPOCH 139\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.8636e-08\n",
      "RUNNING EPOCH 140\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.3867e-08\n",
      "RUNNING EPOCH 141\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.6579e-08\n",
      "RUNNING EPOCH 142\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.5008e-08\n",
      "RUNNING EPOCH 143\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.4433e-08\n",
      "RUNNING EPOCH 144\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.0032e-08\n",
      "RUNNING EPOCH 145\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.0366e-08\n",
      "RUNNING EPOCH 146\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.1733e-07\n",
      "RUNNING EPOCH 147\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.6200e-07\n",
      "RUNNING EPOCH 148\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.3592e-08\n",
      "RUNNING EPOCH 149\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.4223e-08\n",
      "RUNNING EPOCH 150\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.5322e-08\n",
      "RUNNING EPOCH 151\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.5116e-08\n",
      "RUNNING EPOCH 152\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.9484e-08\n",
      "RUNNING EPOCH 153\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.0175e-07\n",
      "RUNNING EPOCH 154\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.0347e-07\n",
      "RUNNING EPOCH 155\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.4302e-07\n",
      "RUNNING EPOCH 156\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.5734e-08\n",
      "RUNNING EPOCH 157\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4191e-07\n",
      "RUNNING EPOCH 158\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.4490e-07\n",
      "RUNNING EPOCH 159\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.8315e-07\n",
      "RUNNING EPOCH 160\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.4619e-07\n",
      "RUNNING EPOCH 161\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3536e-07\n",
      "RUNNING EPOCH 162\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.4388e-08\n",
      "RUNNING EPOCH 163\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.6813e-08\n",
      "RUNNING EPOCH 164\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.4043e-08\n",
      "RUNNING EPOCH 165\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.7881e-08\n",
      "RUNNING EPOCH 166\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.0909e-08\n",
      "RUNNING EPOCH 167\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1040e-07\n",
      "RUNNING EPOCH 168\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.7582e-08\n",
      "RUNNING EPOCH 169\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.5834e-08\n",
      "RUNNING EPOCH 170\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.0620e-07\n",
      "RUNNING EPOCH 171\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6008e-07\n",
      "RUNNING EPOCH 172\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1540e-07\n",
      "RUNNING EPOCH 173\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.3801e-07\n",
      "RUNNING EPOCH 174\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.0290e-07\n",
      "RUNNING EPOCH 175\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.3805e-08\n",
      "RUNNING EPOCH 176\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.1637e-08\n",
      "RUNNING EPOCH 177\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.7331e-07\n",
      "RUNNING EPOCH 178\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.2251e-05\n",
      "RUNNING EPOCH 179\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.0361e-05\n",
      "RUNNING EPOCH 180\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.4771e-05\n",
      "RUNNING EPOCH 181\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3457e-05\n",
      "RUNNING EPOCH 182\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5759e-06\n",
      "RUNNING EPOCH 183\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.0056e-08\n",
      "RUNNING EPOCH 184\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.9282e-08\n",
      "RUNNING EPOCH 185\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.1364e-07\n",
      "RUNNING EPOCH 186\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.6960e-08\n",
      "RUNNING EPOCH 187\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 8.7797e-08\n",
      "RUNNING EPOCH 188\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.7781e-07\n",
      "RUNNING EPOCH 189\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.5345e-07\n",
      "RUNNING EPOCH 190\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.2524e-06\n",
      "RUNNING EPOCH 191\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.0539e-06\n",
      "RUNNING EPOCH 192\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.7382e-06\n",
      "RUNNING EPOCH 193\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.2862e-05\n",
      "RUNNING EPOCH 194\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.0506e-05\n",
      "RUNNING EPOCH 195\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.0366e-06\n",
      "RUNNING EPOCH 196\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.7668e-08\n",
      "RUNNING EPOCH 197\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.9307e-07\n",
      "RUNNING EPOCH 198\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.6384e-08\n",
      "RUNNING EPOCH 199\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.2414e-06\n",
      "RUNNING EPOCH 200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.5317e-07\n",
      "RUNNING EPOCH 201\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.5039e-04\n",
      "RUNNING EPOCH 202\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.2710e-04\n",
      "RUNNING EPOCH 203\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3329\n",
      "RUNNING EPOCH 204\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 15.9416\n",
      "RUNNING EPOCH 205\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 305.3902\n",
      "RUNNING EPOCH 206\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 118.7593\n",
      "RUNNING EPOCH 207\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 402.1207\n",
      "RUNNING EPOCH 208\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 24.1101\n",
      "RUNNING EPOCH 209\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4553\n",
      "RUNNING EPOCH 210\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0734\n",
      "RUNNING EPOCH 211\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "RUNNING EPOCH 212\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.0973e-04\n",
      "RUNNING EPOCH 213\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.3353e-05\n",
      "RUNNING EPOCH 214\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5436e-05\n",
      "RUNNING EPOCH 215\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.5328e-07\n",
      "RUNNING EPOCH 216\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.0775e-08\n",
      "RUNNING EPOCH 217\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3710e-08\n",
      "RUNNING EPOCH 218\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.7973e-08\n",
      "RUNNING EPOCH 219\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.6384e-08\n",
      "RUNNING EPOCH 220\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.0207e-09\n",
      "RUNNING EPOCH 221\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.2354e-08\n",
      "RUNNING EPOCH 222\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.8724e-08\n",
      "RUNNING EPOCH 223\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.3206e-09\n",
      "RUNNING EPOCH 224\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.8405e-09\n",
      "RUNNING EPOCH 225\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.1290e-09\n",
      "RUNNING EPOCH 226\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.2632e-09\n",
      "RUNNING EPOCH 227\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.1893e-08\n",
      "RUNNING EPOCH 228\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.0887e-08\n",
      "RUNNING EPOCH 229\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.8211e-08\n",
      "RUNNING EPOCH 230\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.7615e-08\n",
      "RUNNING EPOCH 231\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3557e-07\n",
      "RUNNING EPOCH 232\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.1556e-08\n",
      "RUNNING EPOCH 233\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3166e-07\n",
      "RUNNING EPOCH 234\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.9468e-08\n",
      "RUNNING EPOCH 235\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.4900e-08\n",
      "RUNNING EPOCH 236\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.6252e-08\n",
      "RUNNING EPOCH 237\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.7906e-08\n",
      "RUNNING EPOCH 238\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.0867e-07\n",
      "RUNNING EPOCH 239\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.3193e-07\n",
      "RUNNING EPOCH 240\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 9.4233e-08\n",
      "RUNNING EPOCH 241\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.3025e-09\n",
      "RUNNING EPOCH 242\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7461e-07\n",
      "RUNNING EPOCH 243\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1336e-06\n",
      "RUNNING EPOCH 244\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.4391e-05\n",
      "RUNNING EPOCH 245\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.7166e-04\n",
      "RUNNING EPOCH 246\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.2726e-04\n",
      "RUNNING EPOCH 247\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.5778e-06\n",
      "RUNNING EPOCH 248\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.9542e-06\n",
      "RUNNING EPOCH 249\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.7215e-07\n",
      "RUNNING EPOCH 250\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.2785e-07\n",
      "RUNNING EPOCH 251\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.0612e-09\n",
      "RUNNING EPOCH 252\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.1530e-09\n",
      "RUNNING EPOCH 253\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.2216e-09\n",
      "RUNNING EPOCH 254\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.2897e-08\n",
      "RUNNING EPOCH 255\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.2336e-08\n",
      "RUNNING EPOCH 256\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.8669e-08\n",
      "RUNNING EPOCH 257\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.9030e-08\n",
      "RUNNING EPOCH 258\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.3185e-08\n",
      "RUNNING EPOCH 259\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.3093e-07\n",
      "RUNNING EPOCH 260\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.8313e-08\n",
      "RUNNING EPOCH 261\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.1726e-08\n",
      "RUNNING EPOCH 262\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.4541e-07\n",
      "RUNNING EPOCH 263\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.4212e-05\n",
      "RUNNING EPOCH 264\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.8781e-05\n",
      "RUNNING EPOCH 265\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.4796e-04\n",
      "RUNNING EPOCH 266\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.2463e-04\n",
      "RUNNING EPOCH 267\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.1244e-05\n",
      "RUNNING EPOCH 268\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.5881e-06\n",
      "RUNNING EPOCH 269\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.8853e-05\n",
      "RUNNING EPOCH 270\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4357e-05\n",
      "RUNNING EPOCH 271\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5740e-05\n",
      "RUNNING EPOCH 272\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.4853e-04\n",
      "RUNNING EPOCH 273\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "RUNNING EPOCH 274\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.8475\n",
      "RUNNING EPOCH 275\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 148.4473\n",
      "RUNNING EPOCH 276\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 213.0788\n",
      "RUNNING EPOCH 277\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.2286\n",
      "RUNNING EPOCH 278\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2524\n",
      "RUNNING EPOCH 279\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0098\n",
      "RUNNING EPOCH 280\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "RUNNING EPOCH 281\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.1925e-04\n",
      "RUNNING EPOCH 282\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.3555e-05\n",
      "RUNNING EPOCH 283\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.8695e-05\n",
      "RUNNING EPOCH 284\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.0181e-05\n",
      "RUNNING EPOCH 285\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.1143e-06\n",
      "RUNNING EPOCH 286\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.8482e-08\n",
      "RUNNING EPOCH 287\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.7056e-08\n",
      "RUNNING EPOCH 288\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.2454e-08\n",
      "RUNNING EPOCH 289\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.6676e-08\n",
      "RUNNING EPOCH 290\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.4379e-07\n",
      "RUNNING EPOCH 291\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.9121e-08\n",
      "RUNNING EPOCH 292\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3545e-07\n",
      "RUNNING EPOCH 293\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.2111e-08\n",
      "RUNNING EPOCH 294\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.5925e-07\n",
      "RUNNING EPOCH 295\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.6169e-06\n",
      "RUNNING EPOCH 296\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.8925e-07\n",
      "RUNNING EPOCH 297\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.5253e-07\n",
      "RUNNING EPOCH 298\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.1951e-07\n",
      "RUNNING EPOCH 299\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.2578e-07\n",
      "RUNNING EPOCH 300\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.4076e-08\n",
      "RUNNING EPOCH 301\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.9604e-08\n",
      "RUNNING EPOCH 302\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.7160e-07\n",
      "RUNNING EPOCH 303\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4022e-07\n",
      "RUNNING EPOCH 304\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.3730e-07\n",
      "RUNNING EPOCH 305\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.5149e-06\n",
      "RUNNING EPOCH 306\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.4267e-06\n",
      "RUNNING EPOCH 307\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.2326e-06\n",
      "RUNNING EPOCH 308\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.4239e-07\n",
      "RUNNING EPOCH 309\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.9798e-07\n",
      "RUNNING EPOCH 310\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.2417e-07\n",
      "RUNNING EPOCH 311\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.7361e-07\n",
      "RUNNING EPOCH 312\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.2933e-06\n",
      "RUNNING EPOCH 313\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.1291e-07\n",
      "RUNNING EPOCH 314\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1532e-06\n",
      "RUNNING EPOCH 315\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.8375e-07\n",
      "RUNNING EPOCH 316\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.2977e-07\n",
      "RUNNING EPOCH 317\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.7186e-07\n",
      "RUNNING EPOCH 318\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.2257e-07\n",
      "RUNNING EPOCH 319\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5373e-05\n",
      "RUNNING EPOCH 320\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.4754e-05\n",
      "RUNNING EPOCH 321\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1096e-04\n",
      "RUNNING EPOCH 322\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4825e-04\n",
      "RUNNING EPOCH 323\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.4942e-04\n",
      "RUNNING EPOCH 324\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "RUNNING EPOCH 325\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.9637\n",
      "RUNNING EPOCH 326\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 84.3925\n",
      "RUNNING EPOCH 327\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 101.7644\n",
      "RUNNING EPOCH 328\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 8.4547\n",
      "RUNNING EPOCH 329\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.8835\n",
      "RUNNING EPOCH 330\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1165\n",
      "RUNNING EPOCH 331\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0438\n",
      "RUNNING EPOCH 332\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0206\n",
      "RUNNING EPOCH 333\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0360\n",
      "RUNNING EPOCH 334\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0153\n",
      "RUNNING EPOCH 335\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "RUNNING EPOCH 336\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.8276e-04\n",
      "RUNNING EPOCH 337\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.0553e-04\n",
      "RUNNING EPOCH 338\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.3766e-05\n",
      "RUNNING EPOCH 339\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.1305e-05\n",
      "RUNNING EPOCH 340\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.4553e-07\n",
      "RUNNING EPOCH 341\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.9242e-08\n",
      "RUNNING EPOCH 342\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.4908e-07\n",
      "RUNNING EPOCH 343\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.5437e-08\n",
      "RUNNING EPOCH 344\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.1337e-08\n",
      "RUNNING EPOCH 345\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.6231e-07\n",
      "RUNNING EPOCH 346\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.9672e-08\n",
      "RUNNING EPOCH 347\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.6467e-08\n",
      "RUNNING EPOCH 348\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.1660e-07\n",
      "RUNNING EPOCH 349\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.7845e-07\n",
      "RUNNING EPOCH 350\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.5082e-06\n",
      "RUNNING EPOCH 351\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.6400e-07\n",
      "RUNNING EPOCH 352\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.8619e-07\n",
      "RUNNING EPOCH 353\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.2804e-06\n",
      "RUNNING EPOCH 354\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.2066e-05\n",
      "RUNNING EPOCH 355\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.5835e-06\n",
      "RUNNING EPOCH 356\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1993e-05\n",
      "RUNNING EPOCH 357\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 9.3952e-05\n",
      "RUNNING EPOCH 358\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.5698e-04\n",
      "RUNNING EPOCH 359\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "RUNNING EPOCH 360\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0314\n",
      "RUNNING EPOCH 361\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "RUNNING EPOCH 362\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "RUNNING EPOCH 363\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4692\n",
      "RUNNING EPOCH 364\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 28.9801\n",
      "RUNNING EPOCH 365\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 11.6776\n",
      "RUNNING EPOCH 366\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 150.1871\n",
      "RUNNING EPOCH 367\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 112.9463\n",
      "RUNNING EPOCH 368\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 70.8869\n",
      "RUNNING EPOCH 369\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.5311\n",
      "RUNNING EPOCH 370\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "RUNNING EPOCH 371\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "RUNNING EPOCH 372\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.8499e-04\n",
      "RUNNING EPOCH 373\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 8.3219e-06\n",
      "RUNNING EPOCH 374\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1734e-06\n",
      "RUNNING EPOCH 375\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.1565e-08\n",
      "RUNNING EPOCH 376\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.4886e-09\n",
      "RUNNING EPOCH 377\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.4341e-08\n",
      "RUNNING EPOCH 378\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.4174e-08\n",
      "RUNNING EPOCH 379\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5395e-07\n",
      "RUNNING EPOCH 380\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.1596e-08\n",
      "RUNNING EPOCH 381\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.9934e-06\n",
      "RUNNING EPOCH 382\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.0258e-06\n",
      "RUNNING EPOCH 383\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.2824e-07\n",
      "RUNNING EPOCH 384\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7308e-08\n",
      "RUNNING EPOCH 385\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.2271e-09\n",
      "RUNNING EPOCH 386\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.7567e-09\n",
      "RUNNING EPOCH 387\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.8179e-09\n",
      "RUNNING EPOCH 388\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.9976e-08\n",
      "RUNNING EPOCH 389\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.2284e-09\n",
      "RUNNING EPOCH 390\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7657e-07\n",
      "RUNNING EPOCH 391\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 8.1382e-08\n",
      "RUNNING EPOCH 392\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.5929e-08\n",
      "RUNNING EPOCH 393\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.5690e-07\n",
      "RUNNING EPOCH 394\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.5380e-08\n",
      "RUNNING EPOCH 395\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.6706e-08\n",
      "RUNNING EPOCH 396\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3815e-07\n",
      "RUNNING EPOCH 397\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.8962e-07\n",
      "RUNNING EPOCH 398\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.9390e-07\n",
      "RUNNING EPOCH 399\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.0644e-07\n",
      "RUNNING EPOCH 400\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.2403e-07\n",
      "RUNNING EPOCH 401\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.9881e-07\n",
      "RUNNING EPOCH 402\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.1696e-08\n",
      "RUNNING EPOCH 403\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.7774e-07\n",
      "RUNNING EPOCH 404\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.8025e-07\n",
      "RUNNING EPOCH 405\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3705e-06\n",
      "RUNNING EPOCH 406\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.7328e-07\n",
      "RUNNING EPOCH 407\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.3751e-07\n",
      "RUNNING EPOCH 408\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.1977e-05\n",
      "RUNNING EPOCH 409\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.3770e-04\n",
      "RUNNING EPOCH 410\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.9558e-04\n",
      "RUNNING EPOCH 411\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.4076e-04\n",
      "RUNNING EPOCH 412\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0504\n",
      "RUNNING EPOCH 413\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1079\n",
      "RUNNING EPOCH 414\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0446\n",
      "RUNNING EPOCH 415\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5552\n",
      "RUNNING EPOCH 416\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.7967\n",
      "RUNNING EPOCH 417\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 204.6417\n",
      "RUNNING EPOCH 418\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 6.8592\n",
      "RUNNING EPOCH 419\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.9210\n",
      "RUNNING EPOCH 420\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1224\n",
      "RUNNING EPOCH 421\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0112\n",
      "RUNNING EPOCH 422\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.1158e-04\n",
      "RUNNING EPOCH 423\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.5731e-04\n",
      "RUNNING EPOCH 424\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.9918e-05\n",
      "RUNNING EPOCH 425\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.0761e-05\n",
      "RUNNING EPOCH 426\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.1790e-06\n",
      "RUNNING EPOCH 427\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.8737e-05\n",
      "RUNNING EPOCH 428\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.4715e-04\n",
      "RUNNING EPOCH 429\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.6345e-05\n",
      "RUNNING EPOCH 430\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.7920e-06\n",
      "RUNNING EPOCH 431\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.4951e-05\n",
      "RUNNING EPOCH 432\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 4.5850e-06\n",
      "RUNNING EPOCH 433\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.6932e-06\n",
      "RUNNING EPOCH 434\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1207e-06\n",
      "RUNNING EPOCH 435\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.9271e-08\n",
      "RUNNING EPOCH 436\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.2629e-08\n",
      "RUNNING EPOCH 437\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.1222e-07\n",
      "RUNNING EPOCH 438\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.3066e-05\n",
      "RUNNING EPOCH 439\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "RUNNING EPOCH 440\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0115\n",
      "RUNNING EPOCH 441\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.1393e-04\n",
      "RUNNING EPOCH 442\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0099\n",
      "RUNNING EPOCH 443\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 9.5430e-04\n",
      "RUNNING EPOCH 444\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1771e-04\n",
      "RUNNING EPOCH 445\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 8.7163e-06\n",
      "RUNNING EPOCH 446\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.8962e-05\n",
      "RUNNING EPOCH 447\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.2893e-05\n",
      "RUNNING EPOCH 448\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.3994e-04\n",
      "RUNNING EPOCH 449\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "RUNNING EPOCH 450\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "RUNNING EPOCH 451\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1849\n",
      "RUNNING EPOCH 452\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.1816\n",
      "RUNNING EPOCH 453\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.0874\n",
      "RUNNING EPOCH 454\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3904\n",
      "RUNNING EPOCH 455\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2266\n",
      "RUNNING EPOCH 456\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.7921\n",
      "RUNNING EPOCH 457\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 43.7556\n",
      "RUNNING EPOCH 458\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 77.2510\n",
      "RUNNING EPOCH 459\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.6749\n",
      "RUNNING EPOCH 460\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3240\n",
      "RUNNING EPOCH 461\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.5184\n",
      "RUNNING EPOCH 462\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 12.9253\n",
      "RUNNING EPOCH 463\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 18.1649\n",
      "RUNNING EPOCH 464\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.8008\n",
      "RUNNING EPOCH 465\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.0734\n",
      "RUNNING EPOCH 466\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.7573\n",
      "RUNNING EPOCH 467\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.7018\n",
      "RUNNING EPOCH 468\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.1786\n",
      "RUNNING EPOCH 469\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3381\n",
      "RUNNING EPOCH 470\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1075\n",
      "RUNNING EPOCH 471\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0449\n",
      "RUNNING EPOCH 472\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "RUNNING EPOCH 473\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "RUNNING EPOCH 474\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "RUNNING EPOCH 475\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "RUNNING EPOCH 476\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0449\n",
      "RUNNING EPOCH 477\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1638\n",
      "RUNNING EPOCH 478\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "RUNNING EPOCH 479\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.8834e-04\n",
      "RUNNING EPOCH 480\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "RUNNING EPOCH 481\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "RUNNING EPOCH 482\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 4.3853e-04\n",
      "RUNNING EPOCH 483\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "RUNNING EPOCH 484\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3363\n",
      "RUNNING EPOCH 485\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.4158\n",
      "RUNNING EPOCH 486\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 5.4790\n",
      "RUNNING EPOCH 487\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 76.8020\n",
      "RUNNING EPOCH 488\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 332.6859\n",
      "RUNNING EPOCH 489\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.9759\n",
      "RUNNING EPOCH 490\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.4551\n",
      "RUNNING EPOCH 491\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0610\n",
      "RUNNING EPOCH 492\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0038\n",
      "RUNNING EPOCH 493\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 6.5588e-04\n",
      "RUNNING EPOCH 494\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.0827e-04\n",
      "RUNNING EPOCH 495\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 7.9780e-05\n",
      "RUNNING EPOCH 496\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.7404e-05\n",
      "RUNNING EPOCH 497\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 2.1572e-07\n",
      "RUNNING EPOCH 498\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 3.3870e-08\n",
      "RUNNING EPOCH 499\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.1497e-07\n",
      "RUNNING EPOCH 500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 3.2113e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 501):\n",
    "    print(f\"RUNNING EPOCH {epoch}\")\n",
    "    hist = model.fit(X_train, y_train, epochs=1)\n",
    "    all_weights = model.layers[0].get_weights()[0].tolist()\n",
    "    for weights in range(len(all_weights)):\n",
    "        for weight in range(len(all_weights[weights])):\n",
    "            history[weights][weight].append(all_weights[weights][weight])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 23:12:16.137700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ms</th>\n",
       "      <th>xs</th>\n",
       "      <th>cs</th>\n",
       "      <th>noise</th>\n",
       "      <th>ys</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>364</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1344</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>2738</td>\n",
       "      <td>2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>264</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>578</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>1786</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>3622</td>\n",
       "      <td>3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "      <td>1310</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>966</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>966</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ms    xs  cs  noise    ys  pred\n",
       "0    2    24  50    100    98    98\n",
       "1    2   364  50     58   778   778\n",
       "2    2  1344  50     35  2738  2738\n",
       "3    2   264  50     29   578   578\n",
       "4    2    90  50     46   230   230\n",
       "..  ..   ...  ..    ...   ...   ...\n",
       "95   2  1786  50     60  3622  3622\n",
       "96   2   104  50     19   258   258\n",
       "97   2   630  50     79  1310  1310\n",
       "98   2   966  50     53  1982  1982\n",
       "99   2   966  50     18  1982  1982\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ms = X_test[\"ms\"].values.tolist()\n",
    "res_xs = X_test[\"xs\"].values.tolist()\n",
    "res_cs = X_test[\"cs\"].values.tolist()\n",
    "res_noise = X_test[\"noise\"].values.tolist()\n",
    "res_pred = [\n",
    "    round(i) for i in model.predict(X_test).flatten().tolist()\n",
    "]\n",
    "res = {\n",
    "    \"ms\": res_ms,\n",
    "    \"xs\": res_xs,\n",
    "    \"cs\": res_cs,\n",
    "    \"noise\": res_noise,\n",
    "    \"ys\": y_test,\n",
    "    \"pred\": res_pred\n",
    "}\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is correct to 100%\n"
     ]
    }
   ],
   "source": [
    "expected = list(res[\"ys\"].values)\n",
    "actual = list(res[\"pred\"].values)\n",
    "accuracies = []\n",
    "for i in range(len(expected)):\n",
    "    if expected[i] > actual[i]:\n",
    "        accuracies.append((actual[i] / expected[i]) * 100)\n",
    "    elif expected[i] < actual[i]:\n",
    "        accuracies.append((expected[i] / actual[i]) * 100)\n",
    "    else:\n",
    "        accuracies.append(100)\n",
    "print(f\"The model is correct to {round(mean(accuracies), 5)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors\n",
    "Setting some nice colors for our following plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "light = \"#90CCF4\"\n",
    "darker = \"#5DA2D5\"\n",
    "important = \"#F3D250\"\n",
    "noise = \"#F78888\"\n",
    "other = \"#ECECEC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animated Bar Graph\n",
    "This shows how the weights of each of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 500\n",
    "fig, ax = plt.subplots(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(i):\n",
    "    ax.cla()\n",
    "    ax.set_xlabel(\"Input Column and Node Number\")\n",
    "    ax.set_ylabel(\"Weight\")\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    m_one = history[0][0][i]\n",
    "    m_two = history[0][1][i]\n",
    "    m_three = history[0][2][i]\n",
    "    m_four = history[0][3][i]\n",
    "\n",
    "    x_one = history[1][0][i]\n",
    "    x_two = history[1][1][i]\n",
    "    x_three = history[1][2][i]\n",
    "    x_four = history[1][3][i]\n",
    "\n",
    "    c_one = history[2][0][i]\n",
    "    c_two = history[2][1][i]\n",
    "    c_three = history[2][2][i]\n",
    "    c_four = history[2][3][i]\n",
    "\n",
    "    noise_one = history[3][0][i]\n",
    "    noise_two = history[3][1][i]\n",
    "    noise_three = history[3][2][i]\n",
    "    noise_four = history[3][3][i]\n",
    "    ax.bar(\n",
    "        [\n",
    "            \"M1\",\n",
    "            \"M2\",\n",
    "            \"M3\",\n",
    "            \"M4\",\n",
    "            \"X1\",\n",
    "            \"X2\",\n",
    "            \"X3\",\n",
    "            \"X4\",\n",
    "            \"C1\",\n",
    "            \"C2\",\n",
    "            \"C3\",\n",
    "            \"C4\",\n",
    "            \"Noise 1\",\n",
    "            \"Noise 2\",\n",
    "            \"Noise 3\",\n",
    "            \"Noise 4\",\n",
    "        ],\n",
    "        [\n",
    "            m_one,\n",
    "            m_two,\n",
    "            m_three,\n",
    "            m_four,\n",
    "            x_one,\n",
    "            x_two,\n",
    "            x_three,\n",
    "            x_four,\n",
    "            c_one,\n",
    "            c_two,\n",
    "            c_three,\n",
    "            c_four,\n",
    "            noise_one,\n",
    "            noise_two,\n",
    "            noise_three,\n",
    "            noise_four,\n",
    "        ],\n",
    "        color=[\n",
    "            darker,\n",
    "            darker,\n",
    "            darker,\n",
    "            darker,\n",
    "            important,\n",
    "            important,\n",
    "            important,\n",
    "            important,\n",
    "            light,\n",
    "            light,\n",
    "            light,\n",
    "            light,\n",
    "            noise,\n",
    "            noise,\n",
    "            noise,\n",
    "            noise,\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animation.FuncAnimation(fig, run, frames=frames, interval=50)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting weights into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(index: int, nodes: int) -> List:\n",
    "    group = []\n",
    "    for i in range(nodes):\n",
    "        group.append(history[index][i])\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = get_groups(0, 4)\n",
    "xs = get_groups(1, 4)\n",
    "cs = get_groups(2, 4)\n",
    "noises = get_groups(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_box_plot(\n",
    "    ax,\n",
    "    data: List,\n",
    "    color: str,\n",
    "    label: str,\n",
    "    position_offset: int = 0,\n",
    "    showfliers: bool = False\n",
    "):\n",
    "    ax.set_xlabel(\"Input Column and Node Number\")\n",
    "    ax.set_ylabel(\"Weight Values\")\n",
    "    color = {\"color\": color}\n",
    "    ax.boxplot(\n",
    "        data,\n",
    "        positions=[i + position_offset for i in range(1,5)],\n",
    "        boxprops=color,\n",
    "        medianprops=color,\n",
    "        whiskerprops=color,\n",
    "        capprops=color,\n",
    "        flierprops={\"markeredgecolor\": other},\n",
    "        showfliers=showfliers,\n",
    "        labels=[f\"{label}{i}\" for i in range(1,5)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "generate_box_plot(ax, ms, darker, \"M\")\n",
    "generate_box_plot(ax, xs, important, \"X\", 4)\n",
    "generate_box_plot(ax, cs, light, \"C\", 8)\n",
    "generate_box_plot(ax, noises, noise, \"Noise\", 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "generate_box_plot(\n",
    "    ax,\n",
    "    ms,\n",
    "    darker,\n",
    "    \"M\",\n",
    "    showfliers=True\n",
    ")\n",
    "generate_box_plot(\n",
    "    ax,\n",
    "    xs,\n",
    "    important,\n",
    "    \"X\",\n",
    "    4,\n",
    "    showfliers=True\n",
    ")\n",
    "generate_box_plot(ax,\n",
    "    cs, light, \"C\", 8, showfliers=True)\n",
    "generate_box_plot(ax,\n",
    "    noises, noise, \"Noise\", 12, showfliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"m_one\": ms[0],\n",
    "    \"m_two\": ms[1],\n",
    "    \"m_three\": ms[2],\n",
    "    \"m_four\": ms[3],\n",
    "    \"x_one\": xs[0],\n",
    "    \"x_two\": xs[1],\n",
    "    \"x_three\": xs[2],\n",
    "    \"x_four\": xs[3],\n",
    "    \"c_one\": cs[0],\n",
    "    \"c_two\": cs[1],\n",
    "    \"c_three\": cs[2],\n",
    "    \"c_four\": cs[3],\n",
    "    \"noise_one\": noises[0],\n",
    "    \"noise_two\": noises[1],\n",
    "    \"noise_three\": noises[2],\n",
    "    \"noise_four\": noises[3]\n",
    "}\n",
    "\n",
    "columns = [\n",
    "    \"m_one\",\n",
    "    \"m_two\",\n",
    "    \"m_three\",\n",
    "    \"m_four\",\n",
    "    \"x_one\",\n",
    "    \"x_two\",\n",
    "    \"x_three\",\n",
    "    \"x_four\",\n",
    "    \"c_one\",\n",
    "    \"c_two\",\n",
    "    \"c_three\",\n",
    "    \"c_four\",\n",
    "    \"noise_one\",\n",
    "    \"noise_two\",\n",
    "    \"noise_three\",\n",
    "    \"noise_four\"\n",
    "]\n",
    "\n",
    "\n",
    "odf = pd.DataFrame(data)\n",
    "odf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = odf.std().to_frame()\n",
    "mean_df = odf.mean().to_frame()\n",
    "std_df.columns = [\"Std\"]\n",
    "mean_df.columns = [\"Mean\"]\n",
    "merged_df = pd.merge(std_df, mean_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.bar(\n",
    "    [\n",
    "        \"M1\",\n",
    "        \"M2\",\n",
    "        \"M3\",\n",
    "        \"M4\",\n",
    "        \"X1\",\n",
    "        \"X2\",\n",
    "        \"X3\",\n",
    "        \"X4\",\n",
    "        \"C1\",\n",
    "        \"C2\",\n",
    "        \"C3\",\n",
    "        \"C4\",\n",
    "        \"Noise 1\",\n",
    "        \"Noise 2\",\n",
    "        \"Noise 3\",\n",
    "        \"Noise 4\",\n",
    "    ],\n",
    "    [\n",
    "        std_df[\"Std\"].loc[\"m_one\"],\n",
    "        std_df[\"Std\"].loc[\"m_two\"],\n",
    "        std_df[\"Std\"].loc[\"m_three\"],\n",
    "        std_df[\"Std\"].loc[\"m_four\"],\n",
    "        std_df[\"Std\"].loc[\"x_one\"],\n",
    "        std_df[\"Std\"].loc[\"x_two\"],\n",
    "        std_df[\"Std\"].loc[\"x_three\"],\n",
    "        std_df[\"Std\"].loc[\"x_four\"],\n",
    "        std_df[\"Std\"].loc[\"c_one\"],\n",
    "        std_df[\"Std\"].loc[\"c_two\"],\n",
    "        std_df[\"Std\"].loc[\"c_three\"],\n",
    "        std_df[\"Std\"].loc[\"c_four\"],\n",
    "        std_df[\"Std\"].loc[\"noise_one\"],\n",
    "        std_df[\"Std\"].loc[\"noise_two\"],\n",
    "        std_df[\"Std\"].loc[\"noise_three\"],\n",
    "        std_df[\"Std\"].loc[\"noise_four\"],\n",
    "    ],\n",
    "    color=[\n",
    "        darker,\n",
    "        darker,\n",
    "        darker,\n",
    "        darker,\n",
    "        important,\n",
    "        important,\n",
    "        important,\n",
    "        important,\n",
    "        light,\n",
    "        light,\n",
    "        light,\n",
    "        light,\n",
    "        noise,\n",
    "        noise,\n",
    "        noise,\n",
    "        noise,\n",
    "    ],\n",
    ")\n",
    "ax.set_xlabel(\"Input Column and Node Number\")\n",
    "ax.set_ylabel(\"Standard Deviation\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ms = sum(\n",
    "    [\n",
    "        std_df[\"Std\"].loc[\"m_one\"],\n",
    "        std_df[\"Std\"].loc[\"m_two\"],\n",
    "        std_df[\"Std\"].loc[\"m_three\"],\n",
    "        std_df[\"Std\"].loc[\"m_four\"],\n",
    "    ]\n",
    ")\n",
    "g_xs = sum(\n",
    "    [\n",
    "        std_df[\"Std\"].loc[\"x_one\"],\n",
    "        std_df[\"Std\"].loc[\"x_two\"],\n",
    "        std_df[\"Std\"].loc[\"x_three\"],\n",
    "        std_df[\"Std\"].loc[\"x_four\"],\n",
    "    ]\n",
    ")\n",
    "g_cs = sum(\n",
    "    [\n",
    "        std_df[\"Std\"].loc[\"c_one\"],\n",
    "        std_df[\"Std\"].loc[\"c_two\"],\n",
    "        std_df[\"Std\"].loc[\"c_three\"],\n",
    "        std_df[\"Std\"].loc[\"c_four\"],\n",
    "    ]\n",
    ")\n",
    "g_noises = sum(\n",
    "    [\n",
    "        std_df[\"Std\"].loc[\"noise_one\"],\n",
    "        std_df[\"Std\"].loc[\"noise_two\"],\n",
    "        std_df[\"Std\"].loc[\"noise_three\"],\n",
    "        std_df[\"Std\"].loc[\"noise_four\"],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.bar(\n",
    "    [\"Ms\", \"Xs\", \"Cs\", \"Noises\"],\n",
    "    [g_ms, g_xs, g_cs, g_noises],\n",
    "    color=[darker, important, light, noise],\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scatter_df(data: List, bin: int, abs: bool = False):\n",
    "    indices = [i for i in range(len(data))]\n",
    "    df = pd.DataFrame(indices, columns=[\"Indices\"])\n",
    "    rdf = pd.DataFrame(data, columns=[\"Readings\"])\n",
    "    if abs:\n",
    "        rdf = rdf.explode(\"Readings\", ignore_index=True).abs()\n",
    "    else:\n",
    "        rdf = rdf.explode(\"Readings\", ignore_index=True)\n",
    "    df[\"Readings\"] = rdf[\"Readings\"]\n",
    "    df[\"Bin\"] = [bin for _ in range(len(data))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_by_node(index: int) -> List:\n",
    "    group = []\n",
    "    for i in list(history.keys()):\n",
    "        group.append(history[i][index])\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_prepare_scatter_df(data: List, abs: bool = False):\n",
    "    dfs = []\n",
    "    for i, item in enumerate(data):\n",
    "        dfs.append(prepare_scatter_df(item, i, abs))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter(scatter_dfs):\n",
    "    _, ax = plt.subplots(figsize=(16, 6))\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Weight\")\n",
    "    colormap = np.array([darker, important, light, noise])\n",
    "    categories = np.array(scatter_dfs[\"Bin\"])\n",
    "    ax.scatter(\n",
    "        x=scatter_dfs[\"Indices\"],\n",
    "        y=scatter_dfs[\"Readings\"],\n",
    "        c=colormap[categories],\n",
    "        s=[2],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [get_group_by_node(i) for i in range(len(history.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    sdf = call_prepare_scatter_df(group, True)\n",
    "    create_scatter(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stds(group):\n",
    "    _, ax = plt.subplots(figsize=(16,6))\n",
    "    domain = np.linspace(-2,2,1000)\n",
    "    means = [mean(group[0]), mean(group[1]), mean(group[2]), mean(group[3])]\n",
    "    stds = [stdev(group[0]), stdev(group[1]), stdev(group[2]), stdev(group[3])]\n",
    "    colors = [darker, important, light, noise]\n",
    "\n",
    "    for mu, std, color in zip(means, stds, colors):\n",
    "        probs = norm.pdf(domain, mu, std)\n",
    "        ax.plot(domain, probs, color=color)\n",
    "        ax.set_xlabel(\"Weight\")\n",
    "        ax.set_ylabel(\"Probability Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    plot_stds(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props(group):\n",
    "    domain = np.linspace(-2,2,1000)\n",
    "    means = [mean(group[0]), mean(group[1]), mean(group[2]), mean(group[3])]\n",
    "    stds = [stdev(group[0]), stdev(group[1]), stdev(group[2]), stdev(group[3])]\n",
    "    results = []\n",
    "    for mu, std in zip(means, stds):\n",
    "        values = []\n",
    "        probs = norm.pdf(domain, mu, std)\n",
    "        for prob in probs:\n",
    "            if math.floor(prob) != 0:\n",
    "                values.append(prob)\n",
    "        results.append(values)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = [get_props(group) for group in groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barrage(all_probs, nodes: int):\n",
    "    res = {\n",
    "        i: {\"len\": 0, \"max\": 0, \"sum\": 0, \"mean\": 0, \"stdev\": 0} for i in range(nodes)\n",
    "    }\n",
    "    for probs in all_probs:\n",
    "        for i, prob in enumerate(probs):\n",
    "            res[i][\"len\"] += len(prob)\n",
    "            res[i][\"max\"] += max(prob)\n",
    "            res[i][\"sum\"] += sum(prob)\n",
    "            res[i][\"mean\"] += mean(prob)\n",
    "            res[i][\"stdev\"] += stdev(prob)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ms\", \"xs\", \"cs\", \"noises\"]\n",
    "\n",
    "res = barrage(all_probs, len(columns))\n",
    "for i in range(len(columns)):\n",
    "    res[columns[i]] = res.pop(i)\n",
    "df = pd.DataFrame(res)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barrage(method: str):\n",
    "    cdict = {\"ms\": light, \"xs\": important, \"cs\": darker, \"noises\": noise}\n",
    "    data = pd.Series(df.loc[method], df.columns).sort_values(ascending=True)\n",
    "    cmap = [cdict[i] for i in list(data.index.values)]\n",
    "    ax = data.plot.barh(width=0.8, figsize=(3, 1), color=cmap)\n",
    "    ax.set_ylabel(\"Input\")\n",
    "    ax.set_xlabel(method.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barrage(\"len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barrage(\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barrage(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barrage(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barrage(\"stdev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('network')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4675c3144d5408229f03762137a1293c1ae58345d8260259851756cf0dcf4741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
