{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance in Neural Networks\n",
    "This site is a companion to the final report on Feature Importance in Neural Networks.\n",
    "\n",
    "The goal of this research was to determine whether the changing values of the weights found between the input layer and first hidden layer of a neural network whilst training could determine feature importance. TL;DR, they can."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Site\n",
    "This site contains exported copies of the notebooks used during the investigation. The following gives a brief overview of each notebook:\n",
    "1. [Overview](./index.html) - Some background details about the site and the work leading to its creation\n",
    "2. [Complete](./complete-example.html) - An end-to-end look at the exploritory work that took place leading up to the use of Probability Density functions to determine the order of feature importance\n",
    "3. [One Value, One Noise](./one-value-one-noise.html) - A comparison of the previous example which attempts to see whether noise is completely cancelled out when there are just two features\n",
    "4. [Accuracy](./accuracy.html) - A look at how accuracy effects the efficacy of the methodology\n",
    "5. [Classification](./classification.html) - So far each example has been for a linear regression whereas this uses a classification example to examine the effect on the outputs\n",
    "6. [Titanic](./titanic.html) - An extension of the Classification example, this time using the ubiquitous Titanic data set. Importantly, it compares the results to a Random Forest classifier which has an inbuilt feature importance method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "The idea was to provide a proof of concept and as such *perfect* data was used throughout the development. By which it is meant that sythetic data was used throughout, with the exception of the [Titanic](./titanic.html) classification page.\n",
    "\n",
    "Specifically, the data followed the equation $y = mx + c$ where **m** and **c** were static values and **x** was randomly selected. In addition to these values, an additional **noise** column was added to give the neural networks a target to tune out. The hypothesis was that the methedology would rank from most to leaast importance the columns in the following order:\n",
    "1. **x** - Since this value has the single largest effect on the result, it should be clearly selected as the most important\n",
    "2. **m/c** - Since these are static, they should be roughly equally weighted in the overall system\n",
    "3. **noise** - Since this has no effect on the output, it should be clearly ranked lowest in importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out the code\n",
    "To try the code in your local environment please clone the repository [here](https://github.com/SkinnyPigeon/weights-in-neural-networks) and follow the instructions in the README"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on Initializers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Late into development, the idea to use initializers to set the starting weights for the models was explored. The early results from this are indeed promising, in that it seems to produce more consistent results. For those interested in running these experiments at home, it may be worth ammending the model definition sections to include this, such as found in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.Zeros()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=FIRST_LAYER, input_shape=[4], kernel_initializer=initializer))\n",
    "model.add(tf.keras.layers.Dense(units=1))\n",
    "model.summary()\n",
    "opt = Adam(0.01)\n",
    "model.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('network')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4675c3144d5408229f03762137a1293c1ae58345d8260259851756cf0dcf4741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
